{"cells":[{"cell_type":"code","execution_count":1,"id":"59fe49dc-cda5-4d22-bb10-49e94cdb6437","metadata":{"chartConfig":{"bar":{"hasRoundedCorners":true,"stacked":false},"type":"bar","version":"v1"},"collapsed":false,"customType":"sql","dataFrameVariableName":"grocery_sales","executionCancelledAt":null,"executionTime":4808,"jupyter":{"outputs_hidden":false,"source_hidden":false},"lastExecutedAt":1722663822192,"lastExecutedByKernel":"225eed24-487a-4790-98ca-2699ebac3f61","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"-- Write your SQL query here\nselect * \nfrom grocery_sales","outputsMetadata":{"0":{"height":317,"type":"dataFrame"}},"sqlCellMode":"dataFrame","sqlSource":{"integrationId":"89e17161-a224-4a8a-846b-0adc0fe7a4b1","integrationType":"postgresql","type":"integration"},"visualizeDataframe":false},"outputs":[],"source":["import pandas as pd\n","import os"]},{"cell_type":"code","execution_count":2,"id":"aa727fb8","metadata":{},"outputs":[],"source":["grocery_sales = pd.read_csv(r'C:\\Users\\Azamat.ma\\Desktop\\ETL\\main\\datalab_export_2024-08-04 12_14_37.csv')"]},{"cell_type":"code","execution_count":10,"id":"c0d64ff1-a4ca-4a82-a8b4-e210244dedc1","metadata":{"executionCancelledAt":null,"executionTime":508,"lastExecutedAt":1722663822700,"lastExecutedByKernel":"225eed24-487a-4790-98ca-2699ebac3f61","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"import pandas as pd\nimport os\n\n# Start here...\n\ndef extract(sales_date, extra_data):\n    extra_df = pd.read_parquet(extra_data)\n    merged_df = sales_date.merge(extra_df, on='index')\n    return merged_df\n\nmerged_df = extract(grocery_sales, \"extra_data.parquet\")\n\n\ndef transform(raw_data):\n    raw_data.fillna(\n    {\n        'CPI':raw_data['CPI'].mean(),\n        'Weekly_Sales': raw_data['Weekly_Sales'].mean(),\n        'Unemployment': raw_data['Unemployment'].mean()\n    }, inplace=True\n    )\n    \n    raw_data['Date'] = pd.to_datetime(raw_data['Date'], format='%Y-%m-%d')\n    raw_data['Month'] = raw_data['Date'].dt.month  # Add this line to extract the month\n    \n    raw_data = raw_data.loc[raw_data[\"Weekly_Sales\"] > 10000, :]\n    \n    raw_data = raw_data.drop([\"index\", \"Temperature\", \"Fuel_Price\", \"MarkDown1\", \"MarkDown2\", \"MarkDown3\", \"MarkDown4\", \"MarkDown5\", \"Type\", \"Size\", \"Date\"], axis = 1)\n    return raw_data\n\nclean_data = transform(merged_df)\n\n\ndef avg_monthly_sales(clean_data):\n    holiday_sales = clean_data[['Month', 'Weekly_Sales']]\n    \n    holiday_sales = (holiday_sales.groupby('Month').agg(Avg_Sales = ('Weekly_Sales', 'mean')).reset_index().round(2))\n    return holiday_sales\n\nagg_data = avg_monthly_sales(clean_data)\nprint(agg_data)\n\ndef load(full_data, full_data_file_path, agg_data, agg_data_file_path):\n    full_data.to_csv(full_data_file_path, index=False)\n    agg_data.to_csv(agg_data_file_path, index=False)\n    \nload(clean_data, \"clean_data.csv\", agg_data, \"agg_data.csv\")\n\n\ndef validation(file_path):\n  \t# Use the \"os\" package to check whether a path exists\n    file_exists = os.path.exists(file_path)\n    # Raise an exception if the path doesn't exist, hence, if there is no file found on a given path\n    if not file_exists:\n        raise Exception(f\"There is no file at the path {file_path}\")\n\n# Call the validation() function and pass first, the cleaned DataFrame path, and then the aggregated DataFrame path\nvalidation(\"clean_data.csv\")\nvalidation(\"agg_data.csv\")","outputsMetadata":{"0":{"height":290,"type":"stream"}}},"outputs":[{"name":"stdout","output_type":"stream","text":["    Month  Avg_Sales\n","0     1.0   40001.26\n","1     2.0   40932.18\n","2     3.0   39731.28\n","3     4.0   40262.77\n","4     5.0   40077.05\n","5     6.0   42214.58\n","6     7.0   40331.23\n","7     8.0   40031.06\n","8     9.0   40219.42\n","9    10.0   39286.29\n","10   11.0   43455.06\n","11   12.0   44893.31\n"]}],"source":["import pandas as pd\n","import os\n","\n","# Start here...\n","\n","def extract(sales_date, extra_data):\n","    extra_df = pd.read_parquet(extra_data)\n","    merged_df = sales_date.merge(extra_df, on='index')\n","    return merged_df\n","\n","merged_df = extract(grocery_sales, \"extra_data.parquet\")\n","\n","\n","def transform(raw_data):\n","    raw_data.fillna(\n","    {\n","        'CPI':raw_data['CPI'].mean(),\n","        'Weekly_Sales': raw_data['Weekly_Sales'].mean(),\n","        'Unemployment': raw_data['Unemployment'].mean()\n","    }, inplace=True\n","    )\n","    \n","    raw_data['Date'] = pd.to_datetime(raw_data['Date'], errors='coerce')\n","    raw_data['Month'] = raw_data['Date'].dt.month  # Add this line to extract the month\n","    \n","    raw_data = raw_data.loc[raw_data[\"Weekly_Sales\"] > 10000, :]\n","    \n","    raw_data = raw_data.drop([\"index\", \"Temperature\", \"Fuel_Price\", \"MarkDown1\", \"MarkDown2\", \"MarkDown3\", \"MarkDown4\", \"MarkDown5\", \"Type\", \"Size\", \"Date\"], axis = 1)\n","    return raw_data\n","\n","clean_data = transform(merged_df)\n","\n","\n","def avg_monthly_sales(clean_data):\n","    holiday_sales = clean_data[['Month', 'Weekly_Sales']]\n","    \n","    holiday_sales = (holiday_sales.groupby('Month').agg(Avg_Sales = ('Weekly_Sales', 'mean')).reset_index().round(2))\n","    return holiday_sales\n","\n","agg_data = avg_monthly_sales(clean_data)\n","print(agg_data)\n","\n","def load(full_data, full_data_file_path, agg_data, agg_data_file_path):\n","    full_data.to_csv(full_data_file_path, index=False)\n","    agg_data.to_csv(agg_data_file_path, index=False)\n","    \n","load(clean_data, \"clean_data.csv\", agg_data, \"agg_data.csv\")\n","\n","\n","def validation(file_path):\n","  \t# Use the \"os\" package to check whether a path exists\n","    file_exists = os.path.exists(file_path)\n","    # Raise an exception if the path doesn't exist, hence, if there is no file found on a given path\n","    if not file_exists:\n","        raise Exception(f\"There is no file at the path {file_path}\")\n","\n","# Call the validation() function and pass first, the cleaned DataFrame path, and then the aggregated DataFrame path\n","validation(\"clean_data.csv\")\n","validation(\"agg_data.csv\")"]},{"cell_type":"code","execution_count":20,"id":"5ad09e9e-268f-4dff-9c37-87c44111a9ef","metadata":{"executionCancelledAt":null,"executionTime":46,"lastExecutedAt":1722663822748,"lastExecutedByKernel":"225eed24-487a-4790-98ca-2699ebac3f61","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":""},"outputs":[],"source":[]}],"metadata":{"colab":{"name":"Welcome to DataCamp Workspaces.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.6"}},"nbformat":4,"nbformat_minor":5}
